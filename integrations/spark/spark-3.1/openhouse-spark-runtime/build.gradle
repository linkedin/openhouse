plugins {
  id 'openhouse.java-minimal-conventions'
  id 'openhouse.maven-publish'
  id 'com.github.johnrengelman.shadow' version '7.1.2'
  id 'scala'
}

ext {
  icebergVersion = rootProject.ext.iceberg_1_2_version
  sparkVersion = '3.1.1'
}

configurations {

  fatJarPackagedDependencies {
    exclude(group: 'org.antlr') // included in spark
    exclude(group: 'org.mapstruct')
  }

  shadow.extendsFrom implementation

  antlr
}


dependencies {
  // Required because we remove antlr plugin dependencies from the compile configuration, see note above
  runtimeOnly "org.antlr:antlr4-runtime:4.7.1"
  antlr "org.antlr:antlr4:4.7.1"

  compileOnly(project(path: ':integrations:java:iceberg-1.2:openhouse-java-runtime', configuration: 'shadow'))
  compileOnly("org.apache.spark:spark-hive_2.12:${sparkVersion}") {
    exclude group: 'org.apache.avro', module: 'avro'
    exclude group: 'org.apache.arrow'
    exclude group: 'io.netty', module: 'netty-buffer'
    exclude group: 'org.roaringbitmap'
    exclude group: 'com.zaxxer', module: 'HikariCP'
    exclude group: 'org.apache.hadoop', module: 'hadoop-client'
  }

  testImplementation("com.linkedin.iceberg:iceberg-spark-runtime-3.1_2.12:" + icebergVersion) {
    exclude group: "io.netty"
  }
  testImplementation(project(':tables-test-fixtures:tables-test-fixtures_2.12')) {
    exclude group: "io.netty"
  }
  testImplementation('org.apache.spark:spark-sql_2.12:' + spark_version){
    // These classes are available from `client-codegen-convention.gradle`
  }
  testImplementation(project(path: ':integrations:java:iceberg-1.2:openhouse-java-runtime', configuration: 'shadow'))

  fatJarPackagedDependencies(project(path: ':integrations:java:iceberg-1.2:openhouse-java-runtime', configuration: 'shadow')) {
    transitive = false
  }
  implementation("com.linkedin.iceberg:iceberg-spark-runtime-3.1_2.12:" + icebergVersion)
}

// Define antlr directories for source generation
ext {
  antlrPackageDirPrefix="com/linkedin/openhouse/spark/sql/catalyst/parser/extensions/"
  antlrMainDir="${projectDir}/src/main/antlr/${antlrPackageDirPrefix}"
  antlrMainGeneratedSrcDir="${project.buildDir}/generated-src/antlr/main/"
}

// Set source for antlr generated directory
sourceSets {
  main {
    java {
      srcDirs antlrMainGeneratedSrcDir
    }
  }
}

// Task to generate java sources using Antlr tool
task runAntlr(type:JavaExec) {
  inputs.dir antlrMainDir
  outputs.dir antlrMainGeneratedSrcDir

  mainClass = "org.antlr.v4.Tool"
  args = ["${antlrMainDir}/OpenhouseSqlExtensions.g4",
          "-visitor",
          "-o", "${antlrMainGeneratedSrcDir}/${antlrPackageDirPrefix}",
          "-package", "com.linkedin.openhouse.spark.sql.catalyst.parser.extensions"]
  maxHeapSize = "64m"
  classpath = configurations.antlr
}

compileJava.dependsOn runAntlr

shadowJar {
  dependencies {
    exclude("javax/**")
  }

  configurations = [project.configurations.fatJarPackagedDependencies]
  mergeServiceFiles()
  archiveClassifier.set('uber')
  zip64 true
}

jar.enabled=true

