"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1899],{2120:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>i,metadata:()=>s,toc:()=>d});var n=t(5893),r=t(1151);const i={title:"Scala",tags:["Spark","Scala","API","OpenHouse","Iceberg"]},o=void 0,s={id:"User Guide/Catalog/Scala",title:"Scala",description:"Data Definition Language (DDL)",source:"@site/docs/User Guide/Catalog/Scala.md",sourceDirName:"User Guide/Catalog",slug:"/User Guide/Catalog/Scala",permalink:"/openhouse/docs/User Guide/Catalog/Scala",draft:!1,unlisted:!1,tags:[{label:"Spark",permalink:"/openhouse/docs/tags/spark"},{label:"Scala",permalink:"/openhouse/docs/tags/scala"},{label:"API",permalink:"/openhouse/docs/tags/api"},{label:"OpenHouse",permalink:"/openhouse/docs/tags/open-house"},{label:"Iceberg",permalink:"/openhouse/docs/tags/iceberg"}],version:"current",frontMatter:{title:"Scala",tags:["Spark","Scala","API","OpenHouse","Iceberg"]},sidebar:"docsSidebar",previous:{title:"SQL",permalink:"/openhouse/docs/User Guide/Catalog/SQL"},next:{title:"Spec",permalink:"/openhouse/docs/User Guide/Catalog/TableSpec"}},l={},d=[{value:"Data Definition Language (DDL)",id:"data-definition-language-ddl",level:2},{value:"Reads",id:"reads",level:2},{value:"With Time-Travel",id:"with-time-travel",level:3},{value:"Writes",id:"writes",level:2},{value:"Create Table",id:"create-table",level:3},{value:"Create Partitioned Table",id:"create-partitioned-table",level:3},{value:"Append Data to Partitioned Table",id:"append-data-to-partitioned-table",level:3},{value:"Overwrite Data",id:"overwrite-data",level:3}];function c(e){const a={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",p:"p",pre:"pre",...(0,r.a)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(a.h2,{id:"data-definition-language-ddl",children:"Data Definition Language (DDL)"}),"\n",(0,n.jsxs)(a.p,{children:["OpenHouse tables supports ",(0,n.jsx)(a.a,{href:"https://iceberg.apache.org/",children:"Apache Iceberg"})," as the underlying table format. You can use native\nSpark syntax to create, alter, and drop tables, but do note there are some constraints OpenHouse imposes."]}),"\n",(0,n.jsxs)(a.p,{children:["For DDLs such as ",(0,n.jsx)(a.code,{children:"CREATE TABLE"}),", ",(0,n.jsx)(a.code,{children:"ALTER TABLE"}),", ",(0,n.jsx)(a.code,{children:"GRANT/REVOKE"})," etc; use ",(0,n.jsx)(a.code,{children:".sql()"})," in SparkSession. You can also use\nnative Spark Scala syntax that creates table if not exists."]}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-sql",children:'import org.apache.spark.sql.functions;\n \n// Your code preparing DataFrame\n \ndf.writeTo("openhouse.<dbName>.<tableName>").create()\n'})}),"\n",(0,n.jsx)(a.p,{children:(0,n.jsx)(a.a,{href:"/openhouse/docs/User%20Guide/Catalog/SQL#data-definition-language-ddl",children:"SQL DDL commands"})}),"\n",(0,n.jsx)(a.h2,{id:"reads",children:"Reads"}),"\n",(0,n.jsx)(a.p,{children:"To query a table, run the following:"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-sql",children:'val df = spark.table("openhouse.db.table")\n'})}),"\n",(0,n.jsx)(a.p,{children:"You can also filter data using custom filters as follows:"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-sql",children:'val filtered_df = df.filter(col("datepartition") > "2022-05-10")\n'})}),"\n",(0,n.jsx)(a.h3,{id:"with-time-travel",children:"With Time-Travel"}),"\n",(0,n.jsxs)(a.p,{children:["Identify older snapshot you want to read, by ",(0,n.jsx)(a.a,{href:"/openhouse/docs/User%20Guide/Catalog/SQL#inspecting-metadata",children:"Inspecting Metadata"}),". Then run the following:"]}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-scala",children:'spark.read.option("snapshot-id", 1031031135387001532L).table("openhouse.db.table")\n'})}),"\n",(0,n.jsx)(a.h2,{id:"writes",children:"Writes"}),"\n",(0,n.jsx)(a.p,{children:"We highly recommend users adopt Apache Spark\u2019s new DataFrameWriterV2 API in Spark 3 when programming with DataFrame API."}),"\n",(0,n.jsx)(a.p,{children:"The following are example Scala statements in Spark 3 to write to a partitioned table."}),"\n",(0,n.jsx)(a.h3,{id:"create-table",children:"Create Table"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-scala",children:'import org.apache.spark.sql.functions;\n\n// Your code preparing DataFrame\n \ndf.writeTo("openhouse.db.table").create()\n'})}),"\n",(0,n.jsx)(a.h3,{id:"create-partitioned-table",children:"Create Partitioned Table"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-scala",children:'import org.apache.spark.sql.functions;\n  \n// Your code to create a table through existing data frame.\n \ndf.sortWithinPartitions("datepartition")\n.writeTo("openhouse.db.table")\n.partitionedBy(functions.col("datepartition"))\n.create()\n'})}),"\n",(0,n.jsx)(a.h3,{id:"append-data-to-partitioned-table",children:"Append Data to Partitioned Table"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-scala",children:'append_df.sortWithinPartitions("datepartition")\n.writeTo("openhouse.db.table")\n.append()\n'})}),"\n",(0,n.jsx)(a.h3,{id:"overwrite-data",children:"Overwrite Data"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-scala",children:'// You can dynamically overwrite partitions, which means\n// any partitions with at least one row matched will be overwritten.\n// To make overwritePartitions work for table-overwrite:\n \noverwrite_df.sortWithinPartitions("datepartition")\n.writeTo("openhouse.db.table")\n.overwritePartitions()\n \n \n// To explicitly overwrite, use the following\noverwrite_df.sortWithinPartitions("datepartition")\n.writeTo("openhouse.db.table")\n.overwrite($"level" === "INFO")\n'})}),"\n",(0,n.jsx)(a.admonition,{type:"note",children:(0,n.jsxs)(a.p,{children:["Note that explicit sort is necessary in partition-write because Spark doesn\u2019t allow Iceberg to request a sort before writing as of Spark 3.0. ",(0,n.jsx)(a.a,{href:"https://iceberg.apache.org/docs/latest/spark-writes/#writing-to-partitioned-tables",children:"See more at link"}),"."]})})]})}function p(e={}){const{wrapper:a}={...(0,r.a)(),...e.components};return a?(0,n.jsx)(a,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}},1151:(e,a,t)=>{t.d(a,{Z:()=>s,a:()=>o});var n=t(7294);const r={},i=n.createContext(r);function o(e){const a=n.useContext(i);return n.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function s(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),n.createElement(i.Provider,{value:a},e.children)}}}]);